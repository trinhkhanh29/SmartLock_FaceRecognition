import cv2
import numpy as np
import os
import sys
import pickle
from datetime import datetime
import firebase_admin
from firebase_admin import credentials, storage
import requests
from dotenv import load_dotenv
import pyttsx3
from facenet_pytorch import MTCNN, InceptionResnetV1
import torch
import time
import traceback
import serial
import pygame
from playsound import playsound

# N·∫°p bi·∫øn m√¥i tr∆∞·ªùng t·ª´ config.env
env_path = os.path.join(os.path.dirname(__file__), '../.env/config.env')
print(f"[DEBUG] ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi c·ªßa .env: {os.path.abspath(env_path)}")
if not os.path.exists(env_path):
    print(f"[ERROR] File .env kh√¥ng t·ªìn t·∫°i t·∫°i: {env_path}")
    sys.exit(1)
else:
    print(f"[INFO] ƒê√£ t√¨m th·∫•y file .env t·∫°i: {env_path}")
    load_dotenv(env_path)

TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
TELEGRAM_CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')
print(f"[DEBUG] TELEGRAM_BOT_TOKEN: {TELEGRAM_BOT_TOKEN}")
print(f"[DEBUG] TELEGRAM_CHAT_ID: {TELEGRAM_CHAT_ID}")

if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
    print("[ERROR] TELEGRAM_BOT_TOKEN ho·∫∑c TELEGRAM_CHAT_ID kh√¥ng ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a trong config.env.")
    sys.exit(1)

# Kh·ªüi t·∫°o Serial
def init_serial(port='COM4', baudrate=115200):
    try:
        ser = serial.Serial(port, baudrate, timeout=1)
        print(f"[INFO] ƒê√£ k·∫øt n·ªëi Serial t·∫°i {port}")
        return ser
    except serial.SerialException as e:
        print(f"[ERROR] Kh√¥ng th·ªÉ k·∫øt n·ªëi Serial: {e}")
        return None

# G·ª≠i l·ªánh Serial
def send_serial_command(ser, command, expected_response=None, timeout=10):
    if ser and ser.is_open:
        try:
            ser.reset_input_buffer()
            ser.write(f"{command}\n".encode())
            print(f"[INFO] ƒê√£ g·ª≠i: {command}, ƒë·ª£i ph·∫£n h·ªìi...")
            start_time = time.time()
            while time.time() - start_time < timeout:
                if ser.in_waiting > 0:
                    response = ser.readline().decode('utf-8').strip()
                    print(f"[INFO] ESP ph·∫£n h·ªìi: {response}")
                    if expected_response is None or expected_response in response:
                        return True
            print("[WARNING] H·∫øt th·ªùi gian ch·ªù ph·∫£n h·ªìi t·ª´ ESP.")
        except serial.SerialException as e:
            print(f"[ERROR] L·ªói Serial: {e}")
    return False
def play_startup_sound(sound_path):
    try:
        pygame.mixer.init()
        pygame.mixer.music.load(sound_path)
        pygame.mixer.music.play()
        print("[INFO] ƒêang ph√°t √¢m thanh kh·ªüi ƒë·ªông...")
        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)
    except Exception as e:
        print(f"[WARNING] Kh√¥ng th·ªÉ ph√°t √¢m thanh: {e}")

# Kh·ªüi t·∫°o engine text-to-speech
def init_tts_engine():
    try:
        engine = pyttsx3.init()
        engine.setProperty('rate', 150)
        engine.setProperty('volume', 1.0)
        voices = engine.getProperty('voices')

        for voice in voices:
            print(f"T√™n gi·ªçng n√≥i: {voice.name}")
            print(f"Ng√¥n ng·ªØ: {voice.languages}")
            print(f"ID gi·ªçng n√≥i: {voice.id}")
            print("---")
            if 'vi' in voice.languages or 'Microsoft An' in voice.name:
                engine.setProperty('voice', voice.id)
                print(f"[INFO] ƒê√£ ch·ªçn gi·ªçng n√≥i: {voice.name}")
                break
        else:
            print("[WARNING] Kh√¥ng t√¨m th·∫•y gi·ªçng n√≥i ti·∫øng Vi·ªát. S·ª≠ d·ª•ng gi·ªçng m·∫∑c ƒë·ªãnh.")
        return engine
    except Exception as e:
        print(f"[WARNING] Kh√¥ng th·ªÉ kh·ªüi t·∫°o engine text-to-speech: {e}")
        return None

# Ki·ªÉm tra token Telegram
def verify_telegram_token():
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/getMe"
    try:
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            print("[INFO] Token Telegram h·ª£p l·ªá.")
            return True
        else:
            print(f"[ERROR] Token Telegram kh√¥ng h·ª£p l·ªá: {response.text}")
            return False
    except requests.exceptions.RequestException as e:
        print(f"[ERROR] Kh√¥ng th·ªÉ x√°c minh token Telegram: {e}")
        return False

# Kh·ªüi t·∫°o Firebase
def initialize_firebase():
    cred_path = os.path.join(os.path.dirname(__file__), '../.env/firebase_credentials.json')
    if not os.path.exists(cred_path):
        raise FileNotFoundError("[ERROR] Firebase credentials file not found.")
    cred = credentials.Certificate(cred_path)
    firebase_admin.initialize_app(cred, {
        'storageBucket': 'smartlockfacerecognition.firebasestorage.app'
    })
    return storage.bucket()

# T·∫£i danh s√°ch t√™n v√† embeddings t·ª´ Firebase ho·∫∑c cache c·ª•c b·ªô
def load_known_faces(bucket, local_dir):
    os.makedirs(local_dir, exist_ok=True)
    embeddings_path = os.path.join(local_dir, "embeddings.pkl")

    # L·∫•y danh s√°ch file tr√™n Firebase
    firebase_files = set(blob.name for blob in bucket.list_blobs(prefix='faces/'))
    print(f"[DEBUG] S·ªë file tr√™n Firebase: {len(firebase_files)}")

    # Ki·ªÉm tra cache embeddings c·ª•c b·ªô
    cached_data = None
    if os.path.exists(embeddings_path):
        try:
            with open(embeddings_path, 'rb') as f:
                cached_data = pickle.load(f)
                known_embeddings, known_ids, known_names, cached_files = cached_data
                print(f"[INFO] ƒê√£ t·∫£i {len(known_ids)} embeddings t·ª´ cache: {embeddings_path}")
                if set(cached_files) == firebase_files:
                    print("[INFO] Cache h·ª£p l·ªá, kh√¥ng c·∫ßn t·∫£i l·∫°i t·ª´ Firebase.")
                    return known_embeddings, known_ids, known_names
                else:
                    print("[INFO] Ph√°t hi·ªán thay ƒë·ªïi trong Firebase, c·∫≠p nh·∫≠t embeddings.")
        except Exception as e:
            print(f"[WARNING] L·ªói khi t·∫£i cache embeddings: {e}. T·∫£i l·∫°i t·ª´ Firebase.")

    # N·∫øu cache kh√¥ng h·ª£p l·ªá ho·∫∑c kh√¥ng t·ªìn t·∫°i, t·∫£i t·ª´ Firebase
    mtcnn = MTCNN(keep_all=False, min_face_size=150, thresholds=[0.7, 0.8, 0.8])
    resnet = InceptionResnetV1(pretrained='vggface2').eval()
    known_embeddings = []
    known_ids = []
    known_names = []
    processed_files = []

    for blob in bucket.list_blobs(prefix='faces/'):
        blob_name = blob.name
        print(f"[DEBUG] X·ª≠ l√Ω file Firebase: {blob_name}")
        try:
            parts = blob_name.split('/')
            if len(parts) < 3:
                print(f"[WARNING] ƒê∆∞·ªùng d·∫´n kh√¥ng h·ª£p l·ªá: {blob_name}")
                continue
            user_id = int(parts[1])
            filename = parts[2]
            user_name_parts = os.path.splitext(filename)[0].split('_')
            if len(user_name_parts) < 4:
                print(f"[WARNING] T√™n file kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng: {filename}")
                continue
            user_name = '_'.join(user_name_parts[1:-2]).replace('_', ' ')
            local_path = os.path.join(local_dir, filename)
            if not os.path.exists(local_path):
                print(f"[DEBUG] T·∫£i file v·ªÅ: {local_path}")
                blob.download_to_filename(local_path)
            else:
                print(f"[DEBUG] S·ª≠ d·ª•ng ·∫£nh c·ª•c b·ªô: {local_path}")
            img = cv2.imread(local_path)
            if img is None:
                print(f"[WARNING] Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {local_path}")
                continue
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            face = mtcnn(img_rgb)
            if face is not None:
                embedding = resnet(face.unsqueeze(0)).detach().numpy()
                known_embeddings.append(embedding)
                known_ids.append(user_id)
                known_names.append(user_name)
                processed_files.append(blob_name)
                print(f"[INFO] ƒê√£ th√™m khu√¥n m·∫∑t: ID={user_id}, Name={user_name}")
            else:
                print(f"[WARNING] Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong: {filename}")
        except (ValueError, IndexError) as e:
            print(f"[WARNING] B·ªè qua file kh√¥ng h·ª£p l·ªá: {blob_name}, {str(e)}")

    # L∆∞u embeddings v√† danh s√°ch file v√†o cache
    if known_embeddings:
        try:
            with open(embeddings_path, 'wb') as f:
                pickle.dump((known_embeddings, known_ids, known_names, processed_files), f)
            print(f"[INFO] ƒê√£ l∆∞u embeddings v√†o: {embeddings_path}")
        except Exception as e:
            print(f"[WARNING] L·ªói khi l∆∞u cache embeddings: {e}")

    return known_embeddings, known_ids, known_names

# T·∫£i m√¥ h√¨nh DNN cho ph√°t hi·ªán khu√¥n m·∫∑t
def get_model_paths():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    cascades_dir = os.path.abspath(os.path.join(base_dir, "..", "cascades"))
    proto_path = os.path.join(cascades_dir, "deploy.prototxt")
    model_path = os.path.join(cascades_dir, "res10_300x300_ssd_iter_140000.caffemodel")
    return proto_path, model_path

def check_model_files():
    proto_path, model_path = get_model_paths()
    if not os.path.exists(proto_path):
        print(f"[ERROR] Kh√¥ng t√¨m th·∫•y file prototxt t·∫°i: {proto_path}")
        print("Vui l√≤ng t·∫£i t·ª´: https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt")
        return False
    if not os.path.exists(model_path):
        print(f"[ERROR] Kh√¥ng t√¨m th·∫•y file model t·∫°i: {model_path}")
        print("Vui l√≤ng t·∫£i t·ª´: https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel")
        return False
    print("[SUCCESS] T·∫•t c·∫£ file m√¥ h√¨nh ƒë√£ s·∫µn s√†ng")
    return True

def load_deep_face_detector():
    proto_path, model_path = get_model_paths()
    if not check_model_files():
        print("[WARNING] S·ª≠ d·ª•ng Haar Cascade thay th·∫ø")
        return None
    try:
        net = cv2.dnn.readNetFromCaffe(proto_path, model_path)
        print("[INFO] ƒê√£ t·∫£i th√†nh c√¥ng DNN model")
        return net
    except Exception as e:
        print(f"[ERROR] L·ªói khi t·∫£i DNN model: {str(e)}")
        return None

def detect_faces_dnn(net, frame, conf_threshold=0.7):
    h, w = frame.shape[:2]
    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))
    net.setInput(blob)
    detections = net.forward()
    faces = []
    min_face_size = 150
    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        if confidence > conf_threshold:
            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
            (x, y, x2, y2) = box.astype("int")
            width, height = x2 - x, y2 - y
            if width >= min_face_size and height >= min_face_size:
                faces.append((x, y, width, height))
    return faces

def send_telegram_message_with_photo(message, photo_path):
    if not message or not isinstance(message, str) or len(message.strip()) == 0:
        print("[ERROR] Tin nh·∫Øn kh√¥ng h·ª£p l·ªá ho·∫∑c r·ªóng, b·ªè qua g·ª≠i Telegram.")
        return False
    if not os.path.exists(photo_path):
        print(f"[ERROR] File ·∫£nh kh√¥ng t·ªìn t·∫°i t·∫°i: {photo_path}")
        return False
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        print("[ERROR] Thi·∫øu TELEGRAM_BOT_TOKEN ho·∫∑c TELEGRAM_CHAT_ID. Ki·ªÉm tra file config.env.")
        return False
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto"
    payload = {'chat_id': TELEGRAM_CHAT_ID, 'caption': message.strip()}
    files = {'photo': open(photo_path, 'rb')}
    try:
        response = requests.post(url, data=payload, files=files, timeout=5)
        if response.status_code != 200:
            print(f"[ERROR] G·ª≠i Telegram th·∫•t b·∫°i: {response.text}")
            return False
        print("[INFO] G·ª≠i tin nh·∫Øn v√† ·∫£nh Telegram th√†nh c√¥ng.")
        return True
    except requests.exceptions.RequestException as e:
        print(f"[ERROR] L·ªói k·∫øt n·ªëi khi g·ª≠i Telegram: {e}")
        return False
    finally:
        files['photo'].close()

def main():
    # Ki·ªÉm tra token Telegram
    if not verify_telegram_token():
        print("[ERROR] Kh√¥ng th·ªÉ ti·∫øp t·ª•c do token Telegram kh√¥ng h·ª£p l·ªá.")
        sys.exit(1)

    # Kh·ªüi t·∫°o TTS
    tts_engine = init_tts_engine()
    ser = init_serial(port='COM4')

    # Bi·∫øn ƒë·∫øm th·∫•t b·∫°i v√† kh√≥a
    fail_count = 0
    lockout_time = 0
    lock_duration = 60  # th·ªùi gian kh√≥a: 60 gi√¢y

    # Bi·∫øn th·ªëng k√™ th·ª±c nghi·ªám
    correct_recognitions = 0
    total_recognitions = 0
    processing_times = []
    false_positives = 0
    false_negatives = 0
    # Placeholder cho t·ªâ l·ªá sai t·ª´ 100 th·ª≠ nghi·ªám (c·∫≠p nh·∫≠t sau khi th·ª≠ nghi·ªám th·ª±c t·∫ø)
    false_positive_rate = 5.0  # % (gi·∫£ ƒë·ªãnh, thay b·∫±ng d·ªØ li·ªáu th·ª±c)
    false_negative_rate = 10.0  # % (gi·∫£ ƒë·ªãnh, thay b·∫±ng d·ªØ li·ªáu th·ª±c)

    try:
        # Kh·ªüi t·∫°o Firebase
        bucket = initialize_firebase()

        # T·∫£i danh s√°ch khu√¥n m·∫∑t ƒë√£ bi·∫øt
        dataset_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "dataset"))
        load_start = time.time()
        known_embeddings, known_ids, known_names = load_known_faces(bucket, dataset_path)
        print(f"[INFO] Th·ªùi gian t·∫£i embeddings: {(time.time() - load_start):.3f}s")
        if not known_embeddings:
            print("[ERROR] Kh√¥ng c√≥ d·ªØ li·ªáu khu√¥n m·∫∑t n√†o t·ª´ Firebase ho·∫∑c cache. Vui l√≤ng thu th·∫≠p d·ªØ li·ªáu tr∆∞·ªõc.")
            sys.exit(1)

        # Kh·ªüi t·∫°o FaceNet
        mtcnn = MTCNN(keep_all=False, min_face_size=150, thresholds=[0.7, 0.8, 0.8])
        resnet = InceptionResnetV1(pretrained='vggface2').eval()

        # N·∫°p b·ªô ph√°t hi·ªán khu√¥n m·∫∑t DNN
        face_detector = load_deep_face_detector()
        if face_detector is None:
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            if face_cascade.empty():
                print("[ERROR] Kh√¥ng th·ªÉ t·∫£i b·ªô ph√°t hi·ªán khu√¥n m·∫∑t.")
                sys.exit(1)
            print("[INFO] S·ª≠ d·ª•ng Haar Cascade do thi·∫øu m√¥ h√¨nh DNN.")

        # Kh·ªüi t·∫°o camera
        cam = cv2.VideoCapture(0)
        if not cam.isOpened():
            print("[ERROR] Kh√¥ng th·ªÉ m·ªü camera.")
            sys.exit(1)
        cam.set(3, 640)
        cam.set(4, 480)
        min_face_size = 150
        optimal_face_size = 200
        print("\n[INFO] Face recognition started. Press ESC to exit.")

        min_face_size = 150
        optimal_face_size = 200
        print("\n[INFO] Face recognition started. Press ESC to exit.")
        frame_count = 0
        start_time = time.time()
        temp_photo_path = os.path.join(os.path.dirname(__file__), "..", "temp", "temp_face.jpg")
        voice_cooldown = 5
        last_voice_time = datetime.now()

        # Ph√°t √¢m thanh kh·ªüi ƒë·ªông khi b·∫≠t camera
        sound_path = os.path.join(os.path.dirname(__file__), '../sound/Ring-Doorbell-Sound.wav')
        if not os.path.exists(sound_path):
            print(f"[ERROR] File √¢m thanh kh√¥ng t·ªìn t·∫°i t·∫°i: {sound_path}")
        else:
            play_startup_sound(sound_path)

        while True:
            try:
                ret, frame = cam.read()
                if not ret:
                    print("[ERROR] Kh√¥ng th·ªÉ ƒë·ªçc khung h√¨nh t·ª´ camera.")
                    break

                frame = cv2.flip(frame, 1)
                frame_count += 1
                elapsed_time = time.time() - start_time
                fps = frame_count / elapsed_time if elapsed_time > 0 else 0
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

                # Ki·ªÉm tra xem c√≥ ƒëang trong th·ªùi gian b·ªã kh√≥a kh√¥ng
                if time.time() < lockout_time:
                    print("[TH√îNG B√ÅO] H·ªá th·ªëng ƒëang b·ªã kh√≥a v√¨ nh·∫≠n di·ªán sai qu√° 3 l·∫ßn.")
                    cv2.putText(frame, "Bi khoa 1 phut - Vui long doi...", (10, 30),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                    cv2.imshow("Face Recognition", frame)
                    if cv2.waitKey(1) & 0xFF == ord("q"):
                        break
                    continue  # B·ªè qua x·ª≠ l√Ω nh·∫≠n di·ªán trong l√∫c b·ªã kh√≥a

                # B·∫Øt ƒë·∫ßu ƒëo th·ªùi gian x·ª≠ l√Ω
                frame_process_start = time.time()

                # Ph√°t hi·ªán khu√¥n m·∫∑t
                process_start = time.time()
                if face_detector is not None:
                    faces = detect_faces_dnn(face_detector, frame)
                else:
                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                    faces = face_cascade.detectMultiScale(
                        gray, scaleFactor=1.1, minNeighbors=6, minSize=(min_face_size, min_face_size)
                    )
                print(f"[DEBUG] S·ªë khu√¥n m·∫∑t ph√°t hi·ªán: {len(faces)}, th·ªùi gian: {(time.time() - process_start):.3f}s")

                current_time = datetime.now()
                time_since_last_voice = (current_time - last_voice_time).total_seconds()

                for (x, y, w, h) in faces:
                    if w < min_face_size or h < min_face_size:
                        print(f"[DEBUG] B·ªè qua khu√¥n m·∫∑t nh·ªè: {w}x{h}")
                        continue

                    # H∆∞·ªõng d·∫´n ng∆∞·ªùi d√πng n·∫øu khu√¥n m·∫∑t nh·ªè
                    if w < optimal_face_size and time_since_last_voice > voice_cooldown and tts_engine:
                        voice_message = "Vui l√≤ng ƒë∆∞a khu√¥n m·∫∑t g·∫ßn h∆°n ƒë·ªÉ nh·∫≠n di·ªán ch√≠nh x√°c"
                        tts_engine.say(voice_message)
                        tts_engine.runAndWait()
                        last_voice_time = current_time
                        print("[VOICE] Ph√°t √¢m thanh h∆∞·ªõng d·∫´n")

                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                    face_img = frame_rgb[y:y + h, x:x + w]
                    recognition_start = time.time()
                    face_tensor = mtcnn(face_img)
                    name = "Unknown"
                    confidence_percent = 0.0
                    color = (255, 255, 255)

                    if face_tensor is not None:
                        embedding = resnet(face_tensor.unsqueeze(0)).detach().numpy()
                        distances = [np.linalg.norm(embedding - emb) for emb in known_embeddings]
                        if distances:
                            min_distance = min(distances)
                            min_idx = distances.index(min_distance)
                            confidence_percent = max(0, min(100, (1 - min_distance / 2) * 100))
                            if min_distance < 0.6:
                                name = known_names[min_idx]
                                color = (0, 255, 0)
                            else:
                                color = (0, 0, 255)
                        print(
                            f"[DEBUG] Nh·∫≠n di·ªán: {name}, ƒê·ªô tin c·∫≠y: {confidence_percent:.1f}%, th·ªùi gian: {(time.time() - recognition_start):.3f}s")

                        # C·∫≠p nh·∫≠t th·ªëng k√™
                        total_recognitions += 1
                        if name != "Unknown":
                            correct_recognitions += 1
                        # Gi·∫£ ƒë·ªãnh false positive/negative (c·∫ßn th·ª≠ nghi·ªám th·ª±c t·∫ø ƒë·ªÉ x√°c ƒë·ªãnh)
                        # V√≠ d·ª•: n·∫øu name != "Unknown" nh∆∞ng th·ª±c t·∫ø l√† ng∆∞·ªùi l·∫° -> false positive
                        # N·∫øu name == "Unknown" nh∆∞ng th·ª±c t·∫ø l√† ng∆∞·ªùi quen -> false negative
                        # C·∫≠p nh·∫≠t sau khi c√≥ d·ªØ li·ªáu th·ª±c nghi·ªám

                    now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    if name != "Unknown":
                        fail_count = 0  # Reset fail count on successful recognition
                        cv2.imwrite(temp_photo_path, frame)
                        message = f"[‚úÖ {now_str}] M·ªü c·ª≠a th√†nh c√¥ng - {name} (ƒê·ªô tin c·∫≠y: {confidence_percent:.1f}%)"
                        if send_telegram_message_with_photo(message, temp_photo_path):
                            if tts_engine:
                                send_serial_command(ser, "SUCCESS")
                                voice_message = f"Xin ch√†o {name}. ƒê√£ nh·∫≠n di·ªán th√†nh c√¥ng. M·ªü c·ª≠a"
                                tts_engine.say(voice_message)
                                tts_engine.runAndWait()
                            print("[VOICE] Ph√°t √¢m thanh ch√†o m·ª´ng")
                            print("[INFO] ƒê√£ g·ª≠i th√¥ng b√°o m·ªü c·ª≠a. Tho√°t ch∆∞∆°ng tr√¨nh.")
                            return
                    elif time_since_last_voice > voice_cooldown and tts_engine:
                        fail_count += 1  # Increment fail count for unknown face
                        print(f"[C·∫¢NH B√ÅO] Nh·∫≠n di·ªán th·∫•t b·∫°i {fail_count}/3")
                        cv2.imwrite(temp_photo_path, frame)
                        message = f"[üö® {now_str}] C·∫¢NH B√ÅO: Ph√°t hi·ªán ng∆∞·ªùi l·∫° - ƒê·ªô tin c·∫≠y th·∫•p ({confidence_percent:.1f}%)"
                        if send_telegram_message_with_photo(message, temp_photo_path):
                            send_serial_command(ser, "FAIL")
                            voice_message = "C·∫£nh b√°o! Ph√°t hi·ªán ng∆∞·ªùi l·∫°"
                            tts_engine.say(voice_message)
                            tts_engine.runAndWait()
                            print("[VOICE] Ph√°t √¢m thanh c·∫£nh b√°o")
                            last_voice_time = current_time

                        # Check if failed 3 times
                        if fail_count >= 3:
                            lockout_time = time.time() + lock_duration
                            fail_count = 0
                            print("[B·∫¢O M·∫¨T] H·ªá th·ªëng b·ªã kh√≥a trong 1 ph√∫t.")
                            if tts_engine:
                                tts_engine.say("H·ªá th·ªëng b·ªã kh√≥a trong m·ªôt ph√∫t do nh·∫≠n di·ªán sai qu√° ba l·∫ßn")
                                tts_engine.runAndWait()

                    cv2.putText(frame, name, (x + 5, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
                    cv2.putText(frame, f"{confidence_percent:.1f}%", (x + 5, y + h - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6,
                                (255, 255, 0), 2)

                # T√≠nh th·ªùi gian x·ª≠ l√Ω frame
                frame_process_time = (time.time() - frame_process_start) * 1000  # ms
                processing_times.append(frame_process_time)

                # T√≠nh to√°n th·ªëng k√™
                accuracy = (correct_recognitions / total_recognitions * 100) if total_recognitions > 0 else 0.0
                avg_processing_time = sum(processing_times) / len(processing_times) if processing_times else 0.0

                # Hi·ªÉn th·ªã th·ªëng k√™ tr√™n frame
                cv2.putText(frame, f"FPS: {fps:.1f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
                cv2.putText(frame, f"Accuracy: {accuracy:.1f}%", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                cv2.putText(frame, f"Proc Time: {avg_processing_time:.1f} ms", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                cv2.putText(frame, f"FP Rate: {false_positive_rate:.1f}%", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                cv2.putText(frame, f"FN Rate: {false_negative_rate:.1f}%", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

                cv2.imshow('Face Recognition - FaceNet DNN', frame)

                key = cv2.waitKey(10)
                if key == 27 or key == ord('q'):
                    break

            except KeyboardInterrupt:
                print("\n[INFO] Program interrupted by user.")
                break
            except Exception as e:
                print(f"[ERROR] L·ªói trong v√≤ng l·∫∑p ch√≠nh: {str(e)}")
                print(f"[DEBUG] Traceback: {traceback.format_exc()}")
                continue

    finally:
        # In th·ªëng k√™ cu·ªëi c√πng
        accuracy = (correct_recognitions / total_recognitions * 100) if total_recognitions > 0 else 0.0
        avg_processing_time = sum(processing_times) / len(processing_times) if processing_times else 0.0
        print("\n[TH·ªêNG K√ä TH·ª∞C NGHI·ªÜM]")
        print(f"ƒê·ªô ch√≠nh x√°c: {accuracy:.1f}%")
        print(f"T·ªëc ƒë·ªô x·ª≠ l√Ω trung b√¨nh: {avg_processing_time:.1f} ms/frame")
        print(f"T·ªâ l·ªá False Positive (trong 100 th·ª≠ nghi·ªám): {false_positive_rate:.1f}%")
        print(f"T·ªâ l·ªá False Negative (trong 100 th·ª≠ nghi·ªám): {false_negative_rate:.1f}%")
        print(f"T·ªïng s·ªë nh·∫≠n di·ªán: {total_recognitions}")
        print(f"Nh·∫≠n di·ªán ƒë√∫ng: {correct_recognitions}")

        if os.path.exists(temp_photo_path):
            try:
                os.remove(temp_photo_path)
                print(f"[INFO] ƒê√£ x√≥a file ·∫£nh t·∫°m: {temp_photo_path}")
            except Exception as e:
                print(f"[ERROR] Kh√¥ng th·ªÉ x√≥a file ·∫£nh t·∫°m: {str(e)}")
        if 'cam' in locals() and cam.isOpened():
            cam.release()
        cv2.destroyAllWindows()
        print("\n[INFO] Program exited cleanly.")

if __name__ == "__main__":
    main()
