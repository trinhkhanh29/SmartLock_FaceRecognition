import cv2
import numpy as np
import os
import sys
import pickle
from datetime import datetime
import firebase_admin
from firebase_admin import credentials, storage
import requests
from dotenv import load_dotenv
import pyttsx3
from facenet_pytorch import MTCNN, InceptionResnetV1
import torch
import time
import traceback

# N·∫°p bi·∫øn m√¥i tr∆∞·ªùng t·ª´ config.env
env_path = os.path.join(os.path.dirname(__file__), '../.env/config.env')
print(f"[DEBUG] ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi c·ªßa .env: {os.path.abspath(env_path)}")
if not os.path.exists(env_path):
    print(f"[ERROR] File .env kh√¥ng t·ªìn t·∫°i t·∫°i: {env_path}")
    sys.exit(1)
else:
    print(f"[INFO] ƒê√£ t√¨m th·∫•y file .env t·∫°i: {env_path}")
    load_dotenv(env_path)

TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
TELEGRAM_CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')
print(f"[DEBUG] TELEGRAM_BOT_TOKEN: {TELEGRAM_BOT_TOKEN}")
print(f"[DEBUG] TELEGRAM_CHAT_ID: {TELEGRAM_CHAT_ID}")

if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
    print("[ERROR] TELEGRAM_BOT_TOKEN ho·∫∑c TELEGRAM_CHAT_ID kh√¥ng ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a trong config.env.")
    sys.exit(1)


# Kh·ªüi t·∫°o engine text-to-speech
def init_tts_engine():
    try:
        engine = pyttsx3.init()
        engine.setProperty('rate', 150)
        engine.setProperty('volume', 1.0)
        voices = engine.getProperty('voices')
        for voice in voices:
            print(f"T√™n gi·ªçng n√≥i: {voice.name}")
            print(f"Ng√¥n ng·ªØ: {voice.languages}")
            print(f"ID gi·ªçng n√≥i: {voice.id}")
            print("---")
            if 'vi' in voice.languages or 'Microsoft An' in voice.name:
                engine.setProperty('voice', voice.id)
                print(f"[INFO] ƒê√£ ch·ªçn gi·ªçng n√≥i: {voice.name}")
                break
        else:
            print("[WARNING] Kh√¥ng t√¨m th·∫•y gi·ªçng n√≥i ti·∫øng Vi·ªát. S·ª≠ d·ª•ng gi·ªçng m·∫∑c ƒë·ªãnh.")
        return engine
    except Exception as e:
        print(f"[WARNING] Kh√¥ng th·ªÉ kh·ªüi t·∫°o engine text-to-speech: {e}")
        return None


# Ki·ªÉm tra token Telegram
def verify_telegram_token():
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/getMe"
    try:
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            print("[INFO] Token Telegram h·ª£p l·ªá.")
            return True
        else:
            print(f"[ERROR] Token Telegram kh√¥ng h·ª£p l·ªá: {response.text}")
            return False
    except requests.exceptions.RequestException as e:
        print(f"[ERROR] Kh√¥ng th·ªÉ x√°c minh token Telegram: {e}")
        return False


# Kh·ªüi t·∫°o Firebase
def initialize_firebase():
    cred_path = os.path.join(os.path.dirname(__file__), '../.env/firebase_credentials.json')
    if not os.path.exists(cred_path):
        raise FileNotFoundError("[ERROR] Firebase credentials file not found.")
    cred = credentials.Certificate(cred_path)
    firebase_admin.initialize_app(cred, {
        'storageBucket': 'smartlockfacerecognition.firebasestorage.app'
    })
    return storage.bucket()


# T·∫£i danh s√°ch t√™n v√† embeddings t·ª´ Firebase ho·∫∑c cache c·ª•c b·ªô
def load_known_faces(bucket, local_dir):
    os.makedirs(local_dir, exist_ok=True)
    embeddings_path = os.path.join(local_dir, "embeddings.pkl")

    # L·∫•y danh s√°ch file tr√™n Firebase
    firebase_files = set(blob.name for blob in bucket.list_blobs(prefix='faces/'))
    print(f"[DEBUG] S·ªë file tr√™n Firebase: {len(firebase_files)}")

    # Ki·ªÉm tra cache embeddings c·ª•c b·ªô
    cached_data = None
    if os.path.exists(embeddings_path):
        try:
            with open(embeddings_path, 'rb') as f:
                cached_data = pickle.load(f)
                known_embeddings, known_ids, known_names, cached_files = cached_data
                print(f"[INFO] ƒê√£ t·∫£i {len(known_ids)} embeddings t·ª´ cache: {embeddings_path}")
                if set(cached_files) == firebase_files:
                    print("[INFO] Cache h·ª£p l·ªá, kh√¥ng c·∫ßn t·∫£i l·∫°i t·ª´ Firebase.")
                    return known_embeddings, known_ids, known_names
                else:
                    print("[INFO] Ph√°t hi·ªán thay ƒë·ªïi trong Firebase, c·∫≠p nh·∫≠t embeddings.")
        except Exception as e:
            print(f"[WARNING] L·ªói khi t·∫£i cache embeddings: {e}. T·∫£i l·∫°i t·ª´ Firebase.")

    # N·∫øu cache kh√¥ng h·ª£p l·ªá ho·∫∑c kh√¥ng t·ªìn t·∫°i, t·∫£i t·ª´ Firebase
    mtcnn = MTCNN(keep_all=False, min_face_size=150, thresholds=[0.7, 0.8, 0.8])
    resnet = InceptionResnetV1(pretrained='vggface2').eval()
    known_embeddings = []
    known_ids = []
    known_names = []
    processed_files = []

    for blob in bucket.list_blobs(prefix='faces/'):
        blob_name = blob.name
        print(f"[DEBUG] X·ª≠ l√Ω file Firebase: {blob_name}")
        try:
            parts = blob_name.split('/')
            if len(parts) < 3:
                print(f"[WARNING] ƒê∆∞·ªùng d·∫´n kh√¥ng h·ª£p l·ªá: {blob_name}")
                continue
            user_id = int(parts[1])
            filename = parts[2]
            # Simplified user_name extraction
            user_name_parts = os.path.splitext(filename)[0].split('_')
            if len(user_name_parts) < 4:
                print(f"[WARNING] T√™n file kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng: {filename}")
                continue
            user_name = '_'.join(user_name_parts[1:-2]).replace('_', ' ')
            local_path = os.path.join(local_dir, filename)
            if not os.path.exists(local_path):
                print(f"[DEBUG] T·∫£i file v·ªÅ: {local_path}")
                blob.download_to_filename(local_path)
            else:
                print(f"[DEBUG] S·ª≠ d·ª•ng ·∫£nh c·ª•c b·ªô: {local_path}")
            img = cv2.imread(local_path)
            if img is None:
                print(f"[WARNING] Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {local_path}")
                continue
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            face = mtcnn(img_rgb)
            if face is not None:
                embedding = resnet(face.unsqueeze(0)).detach().numpy()
                known_embeddings.append(embedding)
                known_ids.append(user_id)
                known_names.append(user_name)
                processed_files.append(blob_name)
                print(f"[INFO] ƒê√£ th√™m khu√¥n m·∫∑t: ID={user_id}, Name={user_name}")
            else:
                print(f"[WARNING] Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong: {filename}")
        except (ValueError, IndexError) as e:
            print(f"[WARNING] B·ªè qua file kh√¥ng h·ª£p l·ªá: {blob_name}, {str(e)}")

    # L∆∞u embeddings v√† danh s√°ch file v√†o cache
    if known_embeddings:
        try:
            with open(embeddings_path, 'wb') as f:
                pickle.dump((known_embeddings, known_ids, known_names, processed_files), f)
            print(f"[INFO] ƒê√£ l∆∞u embeddings v√†o: {embeddings_path}")
        except Exception as e:
            print(f"[WARNING] L·ªói khi l∆∞u cache embeddings: {e}")

    return known_embeddings, known_ids, known_names


# T·∫£i m√¥ h√¨nh DNN cho ph√°t hi·ªán khu√¥n m·∫∑t
def get_model_paths():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    cascades_dir = os.path.abspath(os.path.join(base_dir, "..", "cascades"))
    proto_path = os.path.join(cascades_dir, "deploy.prototxt")
    model_path = os.path.join(cascades_dir, "res10_300x300_ssd_iter_140000.caffemodel")
    return proto_path, model_path


def check_model_files():
    proto_path, model_path = get_model_paths()
    if not os.path.exists(proto_path):
        print(f"[ERROR] Kh√¥ng t√¨m th·∫•y file prototxt t·∫°i: {proto_path}")
        print(
            "Vui l√≤ng t·∫£i t·ª´: https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt")
        return False
    if not os.path.exists(model_path):
        print(f"[ERROR] Kh√¥ng t√¨m th·∫•y file model t·∫°i: {proto_path}")
        print(
            "Vui l√≤ng t·∫£i t·ª´: https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel")
        return False
    print("[SUCCESS] T·∫•t c·∫£ file m√¥ h√¨nh ƒë√£ s·∫µn s√†ng")
    return True


def load_deep_face_detector():
    proto_path, model_path = get_model_paths()
    if not check_model_files():
        print("[WARNING] S·ª≠ d·ª•ng Haar Cascade thay th·∫ø")
        return None
    try:
        net = cv2.dnn.readNetFromCaffe(proto_path, model_path)
        print("[INFO] ƒê√£ t·∫£i th√†nh c√¥ng DNN model")
        return net
    except Exception as e:
        print(f"[ERROR] L·ªói khi t·∫£i DNN model: {str(e)}")
        return None


def detect_faces_dnn(net, frame, conf_threshold=0.7):
    h, w = frame.shape[:2]
    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))
    net.setInput(blob)
    detections = net.forward()
    faces = []
    min_face_size = 150
    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        if confidence > conf_threshold:
            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
            (x, y, x2, y2) = box.astype("int")
            width, height = x2 - x, y2 - y
            if width >= min_face_size and height >= min_face_size:
                faces.append((x, y, width, height))
    return faces


def send_telegram_message_with_photo(message, photo_path):
    if not message or not isinstance(message, str) or len(message.strip()) == 0:
        print("[ERROR] Tin nh·∫Øn kh√¥ng h·ª£p l·ªá ho·∫∑c r·ªóng, b·ªè qua g·ª≠i Telegram.")
        return False
    if not os.path.exists(photo_path):
        print(f"[ERROR] File ·∫£nh kh√¥ng t·ªìn t·∫°i t·∫°i: {photo_path}")
        return False
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        print("[ERROR] Thi·∫øu TELEGRAM_BOT_TOKEN ho·∫∑c TELEGRAM_CHAT_ID. Ki·ªÉm tra file config.env.")
        return False
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto"
    payload = {'chat_id': TELEGRAM_CHAT_ID, 'caption': message.strip()}
    files = {'photo': open(photo_path, 'rb')}
    try:
        response = requests.post(url, data=payload, files=files, timeout=5)
        if response.status_code != 200:
            print(f"[ERROR] G·ª≠i Telegram th·∫•t b·∫°i: {response.text}")
            return False
        print("[INFO] G·ª≠i tin nh·∫Øn v√† ·∫£nh Telegram th√†nh c√¥ng.")
        return True
    except requests.exceptions.RequestException as e:
        print(f"[ERROR] L·ªói k·∫øt n·ªëi khi g·ª≠i Telegram: {e}")
        return False
    finally:
        files['photo'].close()


def main():
    # Ki·ªÉm tra token Telegram
    if not verify_telegram_token():
        print("[ERROR] Kh√¥ng th·ªÉ ti·∫øp t·ª•c do token Telegram kh√¥ng h·ª£p l·ªá.")
        sys.exit(1)

    # Kh·ªüi t·∫°o TTS
    tts_engine = init_tts_engine()

    try:
        # Kh·ªüi t·∫°o Firebase
        bucket = initialize_firebase()

        # T·∫£i danh s√°ch khu√¥n m·∫∑t ƒë√£ bi·∫øt
        dataset_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "dataset"))
        load_start = time.time()
        known_embeddings, known_ids, known_names = load_known_faces(bucket, dataset_path)
        print(f"[INFO] Th·ªùi gian t·∫£i embeddings: {(time.time() - load_start):.3f}s")
        if not known_embeddings:
            print("[ERROR] Kh√¥ng c√≥ d·ªØ li·ªáu khu√¥n m·∫∑t n√†o t·ª´ Firebase ho·∫∑c cache. Vui l√≤ng thu th·∫≠p d·ªØ li·ªáu tr∆∞·ªõc.")
            sys.exit(1)

        # Kh·ªüi t·∫°o FaceNet
        mtcnn = MTCNN(keep_all=False, min_face_size=150, thresholds=[0.7, 0.8, 0.8])
        resnet = InceptionResnetV1(pretrained='vggface2').eval()

        # N·∫°p b·ªô ph√°t hi·ªán khu√¥n m·∫∑t DNN
        face_detector = load_deep_face_detector()
        if face_detector is None:
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            if face_cascade.empty():
                print("[ERROR] Kh√¥ng th·ªÉ t·∫£i b·ªô ph√°t hi·ªán khu√¥n m·∫∑t.")
                sys.exit(1)
            print("[INFO] S·ª≠ d·ª•ng Haar Cascade do thi·∫øu m√¥ h√¨nh DNN.")

        # Kh·ªüi t·∫°o camera
        cam = cv2.VideoCapture(1)
        if not cam.isOpened():
            print("[ERROR] Kh√¥ng th·ªÉ m·ªü camera.")
            sys.exit(1)
        cam.set(3, 640)
        cam.set(4, 480)
        min_face_size = 150
        optimal_face_size = 200
        print("\n[INFO] Face recognition started. Press ESC to exit.")

        frame_count = 0
        start_time = time.time()
        temp_photo_path = os.path.join(os.path.dirname(__file__), "..", "temp", "temp_face.jpg")
        voice_cooldown = 5
        last_voice_time = datetime.now()

        while True:
            try:
                ret, frame = cam.read()
                if not ret:
                    print("[ERROR] Kh√¥ng th·ªÉ ƒë·ªçc khung h√¨nh t·ª´ camera.")
                    break

                frame = cv2.flip(frame, 1)
                frame_count += 1
                elapsed_time = time.time() - start_time
                fps = frame_count / elapsed_time if elapsed_time > 0 else 0
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

                # Ph√°t hi·ªán khu√¥n m·∫∑t
                process_start = time.time()
                if face_detector is not None:
                    faces = detect_faces_dnn(face_detector, frame)
                else:
                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                    faces = face_cascade.detectMultiScale(
                        gray, scaleFactor=1.1, minNeighbors=6, minSize=(min_face_size, min_face_size)
                    )
                print(f"[DEBUG] S·ªë khu√¥n m·∫∑t ph√°t hi·ªán: {len(faces)}, th·ªùi gian: {(time.time() - process_start):.3f}s")

                current_time = datetime.now()
                time_since_last_voice = (current_time - last_voice_time).total_seconds()

                for (x, y, w, h) in faces:
                    if w < min_face_size or h < min_face_size:
                        print(f"[DEBUG] B·ªè qua khu√¥n m·∫∑t nh·ªè: {w}x{h}")
                        continue

                    # H∆∞·ªõng d·∫´n ng∆∞·ªùi d√πng n·∫øu khu√¥n m·∫∑t nh·ªè
                    if w < optimal_face_size and time_since_last_voice > voice_cooldown and tts_engine:
                        voice_message = "Vui l√≤ng ƒë∆∞a khu√¥n m·∫∑t g·∫ßn h∆°n ƒë·ªÉ nh·∫≠n di·ªán ch√≠nh x√°c"
                        tts_engine.say(voice_message)
                        tts_engine.runAndWait()
                        last_voice_time = current_time
                        print("[VOICE] Ph√°t √¢m thanh h∆∞·ªõng d·∫´n")

                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                    face_img = frame_rgb[y:y + h, x:x + w]
                    recognition_start = time.time()
                    face_tensor = mtcnn(face_img)
                    name = "Unknown"
                    confidence_percent = 0.0
                    color = (255, 255, 255)

                    if face_tensor is not None:
                        embedding = resnet(face_tensor.unsqueeze(0)).detach().numpy()
                        distances = [np.linalg.norm(embedding - emb) for emb in known_embeddings]
                        if distances:
                            min_distance = min(distances)
                            min_idx = distances.index(min_distance)
                            confidence_percent = max(0, min(100, (1 - min_distance / 2) * 100))
                            if min_distance < 0.6:
                                name = known_names[min_idx]
                                color = (0, 255, 0)
                            else:
                                color = (0, 0, 255)
                        print(
                            f"[DEBUG] Nh·∫≠n di·ªán: {name}, ƒê·ªô tin c·∫≠y: {confidence_percent:.1f}%, th·ªùi gian: {(time.time() - recognition_start):.3f}s")

                    now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    if name != "Unknown":
                        cv2.imwrite(temp_photo_path, frame)
                        message = f"[‚úÖ {now_str}] M·ªü c·ª≠a th√†nh c√¥ng - {name} (ƒê·ªô tin c·∫≠y: {confidence_percent:.1f}%)"
                        if send_telegram_message_with_photo(message, temp_photo_path):
                            if tts_engine:
                                voice_message = f"Xin ch√†o {name}. ƒê√£ nh·∫≠n di·ªán th√†nh c√¥ng. M·ªü c·ª≠a"
                                tts_engine.say(voice_message)
                                tts_engine.runAndWait()
                                print("[VOICE] Ph√°t √¢m thanh ch√†o m·ª´ng")
                            print("[INFO] ƒê√£ g·ª≠i th√¥ng b√°o m·ªü c·ª≠a. Tho√°t ch∆∞∆°ng tr√¨nh.")
                            return
                    elif time_since_last_voice > voice_cooldown and tts_engine:
                        cv2.imwrite(temp_photo_path, frame)
                        message = f"[üö® {now_str}] C·∫¢NH B√ÅO: Ph√°t hi·ªán ng∆∞·ªùi l·∫° - ƒê·ªô tin c·∫≠y th·∫•p ({confidence_percent:.1f}%)"
                        if send_telegram_message_with_photo(message, temp_photo_path):
                            voice_message = "C·∫£nh b√°o! Ph√°t hi·ªán ng∆∞·ªùi l·∫°"
                            tts_engine.say(voice_message)
                            tts_engine.runAndWait()
                            print("[VOICE] Ph√°t √¢m thanh c·∫£nh b√°o")
                            last_voice_time = current_time

                    cv2.putText(frame, name, (x + 5, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
                    cv2.putText(frame, f"{confidence_percent:.1f}%", (x + 5, y + h - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6,
                                (255, 255, 0), 2)

                cv2.putText(frame, f"FPS: {fps:.1f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
                cv2.imshow('Face Recognition - FaceNet DNN', frame)

                key = cv2.waitKey(10)
                if key == 27 or key == ord('q'):
                    break

            except KeyboardInterrupt:
                print("\n[INFO] Program interrupted by user.")
                break
            except Exception as e:
                print(f"[ERROR] L·ªói trong v√≤ng l·∫∑p ch√≠nh: {str(e)}")
                print(f"[DEBUG] Traceback: {traceback.format_exc()}")
                continue

    finally:
        if os.path.exists(temp_photo_path):
            try:
                os.remove(temp_photo_path)
                print(f"[INFO] ƒê√£ x√≥a file ·∫£nh t·∫°m: {temp_photo_path}")
            except Exception as e:
                print(f"[ERROR] Kh√¥ng th·ªÉ x√≥a file ·∫£nh t·∫°m: {str(e)}")
        if 'cam' in locals() and cam.isOpened():
            cam.release()
        cv2.destroyAllWindows()
        print("\n[INFO] Program exited cleanly.")


if __name__ == "__main__":
    main()