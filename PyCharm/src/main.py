#main.py
import os
import sys
import cv2
import requests
from PyQt5 import QtCore, QtWidgets
from PyQt5.QtGui import QImage, QPixmap
from dotenv import load_dotenv

env_path = os.path.join(os.path.dirname(__file__), '../.env/config.env')
if not os.path.exists(env_path):
    print(f"[ERROR] .env file not found at: {env_path}")
else:
    print(f"[INFO] Loading .env file from: {env_path}")
load_dotenv(env_path)

TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
TELEGRAM_CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')

class MainWindow(QtWidgets.QMainWindow):
    def __init__(self, parent=None):
        super(MainWindow, self).__init__(parent)
        self.setupUi(self)

        # Th√™m c√°c kh·ªüi t·∫°o sau:
        self.recognizer = None  # B·ªô nh·∫≠n di·ªán khu√¥n m·∫∑t
        self.names = ['Unknown']  # Danh s√°ch t√™n ng∆∞·ªùi d√πng
        self.min_face_size = 100  # K√≠ch th∆∞·ªõc khu√¥n m·∫∑t t·ªëi thi·ªÉu
        self.optimal_face_size = 200  # K√≠ch th∆∞·ªõc t·ªëi ∆∞u ƒë·ªÉ nh·∫≠n di·ªán

        # Kh·ªüi t·∫°o b·ªô nh·∫≠n di·ªán khu√¥n m·∫∑t
        self.init_face_recognizer()

        # Ki·ªÉm tra v√† load danh s√°ch t√™n t·ª´ file (n·∫øu c√≥)
        self.load_names()
    def setupUi(self, MainWindow):
        # Placeholder for UI setup
        self.setWindowTitle("SmartLock Face Recognition")
        self.setGeometry(100, 100, 800, 600)

        # Initialize label for video display
        self.label = QtWidgets.QLabel(self)
        self.label.setGeometry(50, 50, 640, 480)
        self.label.setStyleSheet("background-color: black;")
        self.label.setAlignment(QtCore.Qt.AlignCenter)

        # Initialize buttons
        self.button_start = QtWidgets.QPushButton("Start", self)
        self.button_start.setGeometry(50, 550, 100, 30)

        self.button_stop = QtWidgets.QPushButton("Stop", self)
        self.button_stop.setGeometry(200, 550, 100, 30)

    def init_face_recognizer(self):
        """Kh·ªüi t·∫°o b·ªô nh·∫≠n di·ªán khu√¥n m·∫∑t"""
        try:
            self.recognizer = cv2.face.LBPHFaceRecognizer_create()
            # Ki·ªÉm tra n·∫øu c√≥ file trainer ƒë√£ t·ªìn t·∫°i
            trainer_path = 'trainer/trainer.yml'
            if os.path.exists(trainer_path):
                self.recognizer.read(trainer_path)
                print("[INFO] ƒê√£ t·∫£i m√¥ h√¨nh nh·∫≠n di·ªán t·ª´ file trainer")
        except Exception as e:
            print(f"[ERROR] Kh√¥ng th·ªÉ kh·ªüi t·∫°o b·ªô nh·∫≠n di·ªán: {e}")

    def load_names(self):
        """T·∫£i danh s√°ch t√™n t·ª´ file (n·∫øu c√≥)"""
        try:
            names_path = 'names.txt'
            if os.path.exists(names_path):
                with open(names_path, 'r') as f:
                    self.names = [line.strip() for line in f.readlines()]
                print(f"[INFO] ƒê√£ t·∫£i danh s√°ch t√™n: {self.names}")
        except Exception as e:
            print(f"[ERROR] Kh√¥ng th·ªÉ t·∫£i danh s√°ch t√™n: {e}")

    def start_video(self):
        # Nh·∫≠p ID khu√¥n m·∫∑t t·ª´ ng∆∞·ªùi d√πng
        if self.face_id is None:
            self.face_id, ok = QtWidgets.QInputDialog.getText(self, 'Input', 'Nh·∫≠p ID Khu√¥n M·∫∑t:')
            if not ok:
                return

        if self.capture is None:
            self.capture = cv2.VideoCapture(0)  # 0 cho camera m·∫∑c ƒë·ªãnh

        # ƒê·∫∑t k√≠ch th∆∞·ªõc h√¨nh ·∫£nh
        self.capture.set(3, 640)  # Chi·ªÅu r·ªông
        self.capture.set(4, 480)  # Chi·ªÅu cao

        self.timer.start(30)  # C·∫≠p nh·∫≠t m·ªói 30 ms

    def stop_video(self):
        self.timer.stop()
        if self.capture:
            self.capture.release()
            self.capture = None
        self.label.clear()  # X√≥a h√¨nh ·∫£nh hi·ªÉn th·ªã
        self.count = 0  # Reset count khi d·ª´ng

    def send_telegram_message(self, message):
        if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
            print("[WARNING] Thi·∫øu c·∫•u h√¨nh Telegram.")
            return

        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        payload = {
            'chat_id': TELEGRAM_CHAT_ID,
            'text': message
        }
        try:
            response = requests.post(url, data=payload)
            if response.status_code != 200:
                print(f"[ERROR] G·ª≠i Telegram th·∫•t b·∫°i: {response.text}")
        except Exception as e:
            print(f"[ERROR] G·ª≠i Telegram g·∫∑p l·ªói: {e}")

    def update_frame(self):
        if self.capture is not None:
            ret, img = self.capture.read()
            if ret:
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                faces = self.face_detector.detectMultiScale(gray, 1.3, 5,
                                                            minSize=(self.min_face_size, self.min_face_size))

                for (x, y, w, h) in faces:
                    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)

                    # N·∫øu ƒëang trong ch·∫ø ƒë·ªô thu th·∫≠p d·ªØ li·ªáu
                    if hasattr(self, 'face_id') and self.face_id:
                        self.count += 1
                        image_path = os.path.join(self.dataset_path, f"dataset.User.{self.face_id}.{self.count}.jpg")
                        cv2.imwrite(image_path, gray[y:y + h, x:x + w])

                        if self.count == 1:
                            message = f"[üîì] ƒêang thu th·∫≠p d·ªØ li·ªáu khu√¥n m·∫∑t, ID: {self.face_id}."
                            self.send_telegram_message(message)

                    # N·∫øu ƒëang trong ch·∫ø ƒë·ªô nh·∫≠n di·ªán
                    elif self.recognizer:
                        face_roi = gray[y:y + h, x:x + w]
                        try:
                            id, confidence = self.recognizer.predict(face_roi)
                            confidence_percent = max(0, min(100, 100 - confidence))

                            if confidence < 70:  # Ng∆∞·ª°ng tin c·∫≠y
                                name = self.names[id] if id < len(self.names) else f"ID_{id}"
                                cv2.putText(img, name, (x + 5, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                                cv2.putText(img, f"{confidence_percent:.1f}%", (x + 5, y + h - 5),
                                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

                                if confidence_percent > 80:  # Ch·ªâ g·ª≠i th√¥ng b√°o khi ƒë·ªô tin c·∫≠y cao
                                    message = f"[üë§] Nh·∫≠n di·ªán: {name} (ID: {id}, ƒê·ªô tin c·∫≠y: {confidence_percent:.1f}%)"
                                    self.send_telegram_message(message)
                        except Exception as e:
                            print(f"[ERROR] L·ªói nh·∫≠n di·ªán: {e}")

                # Hi·ªÉn th·ªã h√¨nh ·∫£nh
                frame_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                h, w, ch = frame_rgb.shape
                q_image = QImage(frame_rgb.data, w, h, ch * w, QImage.Format_RGB888)
                self.label.setPixmap(QPixmap.fromImage(q_image))

                if hasattr(self, 'count') and self.count >= 30:
                    self.stop_video()
                    message = f"[‚úÖ] Ho√†n th√†nh thu th·∫≠p 30 ·∫£nh cho ID: {self.face_id}"
                    self.send_telegram_message(message)

if __name__ == "__main__":
    app = QtWidgets.QApplication(sys.argv)
    window = MainWindow()
    window.show()
    sys.exit(app.exec_())
